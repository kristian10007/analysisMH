{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import math\n",
    "import seaborn as sn\n",
    "import random\n",
    "from scipy import ndarray\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import entropy\n",
    "from config import *\n",
    "from tools import *\n",
    "from revdict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensureDir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Tabelle_mit_Patientennummer_K.xlsx'\n",
    "data=pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.array(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_pandas_display_options() -> None:\n",
    "    \"\"\"Set pandas display options.\"\"\"\n",
    "    # Ref: https://stackoverflow.com/a/52432757/\n",
    "    display = pd.options.display\n",
    "\n",
    "    display.max_columns = 1000\n",
    "    display.max_rows = 1000\n",
    "    display.max_colwidth = 199\n",
    "    display.width = 1000\n",
    "    # display.precision = 2  # set as needed\n",
    "\n",
    "set_pandas_display_options()\n",
    "\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove not needed rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicesToDrop = np.where(data[\"Patient in Tabelle einfügen (1=ja, 0=nein)\"] != 1)\n",
    "data.drop(indicesToDrop[0], axis=0, inplace=True)\n",
    "data=data.drop([\"Patient in Tabelle einfügen (1=ja, 0=nein)\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.rename(columns=rename_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(data_mapping, inplace=True)\n",
    "addToRevDict(data_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in data_mapping_bool_x_is_yes:\n",
    "    data[n] = data[n].fillna(0)\n",
    "    data.replace({n: {'x': 1, 'X': 1}}, inplace=True)\n",
    "    addToRevDict({n: {'ja': 1, 'nein': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in data_mapping_bool_yes_no:\n",
    "    data[n] = data[n].fillna(np.nan)\n",
    "    data.replace({n: map_yes_no}, inplace=True)\n",
    "    addToRevDict({n: {'ja': 1, 'nein': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in data_mapping_x_is_nan:\n",
    "    data[n] = data[n].fillna(np.nan)\n",
    "    data.replace({n: map_x_NaN}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in data_mapping_auto_count:\n",
    "    data[name] = data[name].fillna(0)\n",
    "    mapping = {'x': 0, 'X': 0}\n",
    "    n = 0\n",
    "    for x in set(data[name]):\n",
    "        if type(x) == type(\"abc\") and n not in mapping.keys():\n",
    "            n = n + 1\n",
    "            mapping[x] = n\n",
    "\n",
    "    data.replace({name: mapping}, inplace=True)\n",
    "    addToRevDict({name: mapping})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({\n",
    "    c_Geburten: {'x': np.nan, 'ja (keine genauen angaben)': np.nan}\n",
    "    , c_po_Tag_dialysefrei: {n: np.nan for n in ['x',  'weiter', 'immer noch', 'ja', '11?', '?', 'mehrere', 'nein']}\n",
    "    , c_Diabetes_mellitus: {'ja, posttransplantionsdiabetes': 1}\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[c_Range_Gestorben] = -np.array(\n",
    "    (data['OP-Tag'].apply(lambda x: x.date())\n",
    "     - pd.to_datetime(data[\"gestorben\"]).apply(lambda x: x.date())\n",
    "    ).dt.days)\n",
    "data[c_Range_Gestorben] = data[c_Range_Gestorben].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixDate(x):\n",
    "    if type(x) == type(7):\n",
    "        x = pd.to_datetime(f\"{x}-01-01\")\n",
    "    return x\n",
    "\n",
    "data[c_Datum_Explantation] = data[c_Datum_Explantation].apply(fixDate)\n",
    "\n",
    "range_explantation_array = -np.array(\n",
    "        (data[c_OP_Tag].apply(lambda x: x.date())\n",
    "         - pd.to_datetime(data[c_Datum_Explantation]).apply(lambda x: x.date())\n",
    "        ).dt.days)\n",
    "\n",
    "data[c_Range_Explantation] = range_explantation_array\n",
    "\n",
    "patients_with_explantation_within_a_year = np.where(range_explantation_array<365)\n",
    "\n",
    "data.drop(patients_with_explantation_within_a_year[0], axis=0, inplace=True)\n",
    "\n",
    "data[c_Range_Explantation] = data[c_Range_Explantation].fillna(-1)\n",
    "\n",
    "data = data.drop([c_OP_Tag, c_Datum_Explantation],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorderByCount(data, c_Grund_fuer_TX, splitBy=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_dict = {'x': np.nan}\n",
    "for x in data[c_Dauer_in_Minuten]:\n",
    "    if type(x) != type(7) and type(x) != type(7.3) and x != 'x':\n",
    "        cleanup_dict[x] = (60.0 * x.hour) + (1.0 * x.minute)\n",
    "\n",
    "data.replace({c_Dauer_in_Minuten: cleanup_dict}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[c_Rh_Compatibility] = 1 * (np.array(data[c_Rh_Empfaenger]) + np.array(data[c_Rh_Spender]) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorderByCount(data, c_Todesursache, splitBy=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Mann auf Frau'] = data['Mann auf Frau'].fillna(0)\n",
    "data['Frau auf Mann'] = data['Frau auf Mann'].fillna(0)\n",
    "data['Frau auf Frau'] = data['Frau auf Frau'].fillna(0)\n",
    "data['Mann auf Mann'] = data['Mann auf Mann'].fillna(0)\n",
    "\n",
    "cleanup_nums = { 'Mann auf Frau': {'x': 1, ' ':0}\n",
    "               , 'Frau auf Mann': {'x': 2, 'X':2}\n",
    "               , 'Frau auf Frau': {'x': 3}\n",
    "               , 'Mann auf Mann': {'x': 4}\n",
    "               }\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "data['MaFr1FrMa2FrFr3MaMa4'] = data['Mann auf Mann'] + data['Frau auf Frau'] + data['Frau auf Mann'] + data['Mann auf Frau']\n",
    "data=data.drop(['Mann auf Frau', 'Frau auf Mann', 'Frau auf Frau', 'Mann auf Mann'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitByCount(data, c_Banff, splitBy=5, fillNaValueBefore=0)\n",
    "set(data[c_Banff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorderByCount(data, c_Grad, splitBy=5, defaultValue=-1)\n",
    "\n",
    "zero_indexes_Banff = data[c_Grad].loc[data[c_Grad]==0].index\n",
    "for i in range(len(data[c_Grad])):\n",
    "    if i in zero_indexes_Banff:\n",
    "           data.at[i,c_Grad] = 0\n",
    "            \n",
    "data[c_Grad] = data[c_Grad].fillna(-1)\n",
    "\n",
    "set(data[c_Grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {}\n",
    "\n",
    "data[c_Malignom_nach_OP] = data[c_Malignom_nach_OP].fillna(0)\n",
    "mapping = { 'x': 1, 'X': 1, 'kein': 0, 'keine': 0, 'kein ': 0, 'keine ': 0 }\n",
    "for n in set(data[c_Malignom_nach_OP]):\n",
    "    if n not in mapping.keys():\n",
    "        mapping[n] = 1\n",
    "        \n",
    "cleanup_nums[c_Malignom_nach_OP] = mapping\n",
    "\n",
    "mapping = {}\n",
    "for n in set(data[c_post_OP_Dialysen]):\n",
    "    if type(n) != type(7):\n",
    "        mapping[n] = np.nan\n",
    "\n",
    "if len(mapping.keys()) > 0:\n",
    "    cleanup_nums[c_post_OP_Dialysen] = mapping\n",
    "\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "addToRevDict({c_Malignom_nach_OP: {'ja': 1, 'nein': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[c_TC_switch] = data[c_T_C] + data[c_C_T]\n",
    "data = data.drop([c_T_C, c_C_T],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {c_Alter_bei_Spende: {\"3 Monate\": .25}}\n",
    "data.replace(cleanup_nums, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data[c_Ausfuhr_bei_Entlassung].index:\n",
    "    if type(data[c_Ausfuhr_bei_Entlassung][i]) != int:\n",
    "        data.at[i,c_Ausfuhr_bei_Entlassung] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[c_Tacrolimus_Spiegel_bei_Entlassung] = data[c_Tacrolimus_Spiegel_bei_Entlassung].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[c_Cyc_Spiegel_bei_Entlassung] = data[c_Cyc_Spiegel_bei_Entlassung].fillna(0)\n",
    "cleanup_nums = {c_Cyc_Spiegel_bei_Entlassung: {\"###\": np.nan, 'x': np.nan}}\n",
    "data.replace(cleanup_nums, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.replace('###', np.nan)\n",
    "data=data.replace(' - ', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop([ 'Demenz'\n",
    "               , 'Lebendspende'\n",
    "               , 'gestorben'\n",
    "               , 'Rh Spender'\n",
    "               , 'Rh Empfänger'\n",
    "               ],axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vizlimit=20\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "for feature in list(data.dtypes.index):\n",
    "    if len(data[feature].value_counts())<=vizlimit:\n",
    "        print('Feature name:', feature.upper())\n",
    "        print('\\n')\n",
    "        print(data[feature].value_counts())\n",
    "        col=sn.color_palette(\"Set2\")\n",
    "        ax=data[feature].value_counts().plot.bar(color=col)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        if len(ax.get_xticklabels())>vizlimit:\n",
    "            plt.setp(ax.get_xticklabels(), visible=False)\n",
    "        plt.xlabel(feature, fontsize=25)\n",
    "        plt.show()\n",
    "\n",
    "        if str(data[feature].dtype)=='float64':\n",
    "            print('feature mean:', data[feature].mean())\n",
    "            print('feature median:', data[feature].median())\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_data_pool = list(data.isna().sum().index[data.isna().sum()<4])\n",
    "dense_data = data[dense_data_pool]\n",
    "dense_data = dense_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[np.array(dense_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in data.dtypes.index:\n",
    "    if str(data.dtypes[x]) not in ['float64', 'int64']:\n",
    "        print(f\"{x}: {str(data.dtypes[x])}: \" + str([y for y in set(data[x]) if str(type(y)) != \"<class 'datetime.time'>\"]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix=[]\n",
    "np_dense_data = np.array(dense_data)\n",
    "\n",
    "for i in range(len(np_dense_data)):\n",
    "    dist=[]\n",
    "    for j in range(len(np_dense_data)):\n",
    "        d = distance.euclidean(np_dense_data[i], np_dense_data[j])\n",
    "        dist.append(d)\n",
    "    \n",
    "    neb_list = np.array(dense_data.index)[np.argsort(dist)]\n",
    "    distance_matrix.append(neb_list)\n",
    "\n",
    "distance_matrix = np.array(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_list = [x for x in list(data.columns) if x not in dense_data_pool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_impute_master=[]\n",
    "for feature_name in missing_value_list:\n",
    "    print(f\"{feature_name} ...\")\n",
    "    missing_value_indices = data[data[feature_name].isnull()].index.tolist()\n",
    "    feature_impute_master = []\n",
    "    for index in missing_value_indices:\n",
    "        index_in_dist_mat = np.where(distance_matrix[:,0] == index)[0][0]\n",
    "        value_list = []\n",
    "        for neb_index in distance_matrix[index_in_dist_mat][1:]:\n",
    "            impute_value = data.loc[[neb_index]][feature_name]\n",
    "            try:\n",
    "                _v = float(impute_value) \n",
    "                if float(impute_value) != float(impute_value):\n",
    "                    pass\n",
    "                else:\n",
    "                    value_list.append(float(impute_value))\n",
    "            except  TypeError:\n",
    "                pass\n",
    "            finally:\n",
    "                pass\n",
    "            \n",
    "            if len(value_list) >= 6:\n",
    "                break\n",
    "                \n",
    "        feature_impute_master.append(np.array(value_list))\n",
    "    total_impute_master.append(np.array(feature_impute_master))\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_impute = []\n",
    "for tim_feature in total_impute_master:\n",
    "    feature_impute=[]\n",
    "    for tim_data in tim_feature:\n",
    "        intcounter=0\n",
    "        \n",
    "        if len(tim_data) == 0:\n",
    "            imputed_value = np.nan\n",
    "        else:\n",
    "            all_ints = True\n",
    "            for v in tim_data:\n",
    "                if v - int(v) != 0:\n",
    "                    all_ints = False\n",
    "                    break\n",
    "        \n",
    "            if all_ints:\n",
    "                imputed_value = np.bincount(tim_data.astype(int)).argmax()\n",
    "            else:\n",
    "                imputed_value = np.mean(tim_data)\n",
    "            \n",
    "        feature_impute.append(np.array(imputed_value))\n",
    "\n",
    "    total_impute.append(np.array(feature_impute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, values in zip(missing_value_list, total_impute):\n",
    "    missing_value_indices = data[data[f].isnull()].index.tolist()\n",
    "    for i, v in zip(missing_value_indices, values):\n",
    "        data.at[i, f] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cont_features+nom_features+ord_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmi(groesse, gewicht):\n",
    "    return data[gewicht] / ((data[groesse] / 100) * (data[groesse] / 100))\n",
    "\n",
    "data[c_BMI_Empfaenger] = bmi(c_Gewicht_Empfaener, c_Groesse_Empfaener)\n",
    "data[c_BMI_Spender] = bmi(c_Gewicht_Spender, c_Groesse_Spender)\n",
    "\n",
    "#data=data.drop([c_Gewicht_Empfaener, c_Groesse_Empfaener, c_Gewicht_Spender, c_Groesse_Spender, c_Todspende], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feature_entropies=[]\n",
    "for feature in nom_features+ord_features:\n",
    "    x=entropy(data[feature].value_counts(), base=2)/(len(data[feature].value_counts().index)-1)\n",
    "    cat_feature_entropies.append(x)\n",
    "    print(feature+' '+str(x))\n",
    "cat_feature_entropies=np.array(cat_feature_entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feature_spread=[]\n",
    "for feature in cont_features:\n",
    "    standardardized=(data[feature]-data[feature].mean())/data[feature].std()\n",
    "    x=abs(standardardized.max()-standardardized.min())\n",
    "    cont_feature_spread.append(x)\n",
    "    print(feature+'  '+str(x))\n",
    "cont_feature_spread=np.array(cont_feature_spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_save = [ c_Cell_Myfortic\n",
    "                  , c_Konversion_auf_andere\n",
    "                   , c_Tacrolimus_Spiegel_bei_Entlassung\n",
    "                   , c_Abstossungsreaktion\n",
    "                   , c_Alter_bei_Tx\n",
    "                   , c_Range_Explantation\n",
    "                   , c_Range_Gestorben\n",
    "                   , c_Groesse_Spender\n",
    "                  ]\n",
    "column_backup = {}\n",
    "\n",
    "for c in columns_to_save:\n",
    "    column_backup[c] = data[c]\n",
    "\n",
    "# removing low entropy categorical features\n",
    "data=data.drop(np.array(nom_features+ord_features)[np.where(cat_feature_entropies<np.quantile(cat_feature_entropies,.25))],axis=1)\n",
    "\n",
    "##removing low spread continuous features\n",
    "data=data.drop(np.array(cont_features)[np.where(cont_feature_spread<np.quantile(cont_feature_spread,.25))],axis=1)\n",
    "\n",
    "for c in columns_to_save:\n",
    "    data[c] = column_backup[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(fileName_csv_preprocessed, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labeled_columns = [c_Patientennummer] + cont_features + nom_features + ord_features\n",
    "\n",
    "print(\"Colums with unknown data type:\")\n",
    "for x in data.columns:\n",
    "    if x not in all_labeled_columns:\n",
    "        print(f\"'{x}'\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Colums not in dataset:\")\n",
    "for x in all_labeled_columns:\n",
    "    if x not in data.columns:\n",
    "        print(f\"'{x}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveAutoRevDict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
